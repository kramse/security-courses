\documentclass[Screen16to9,17pt]{foils}
\usepackage{zencurity-slides}
\externaldocument{siem-log-analysis-exercises}
\selectlanguage{english}

\begin{document}

\mytitlepage
{5. Baseline Your Data}
{KEA Kompetence SIEM and Log Analysis}


\slide{Goals for today}

\hlkimage{6cm}{thomas-galler-hZ3uF1-z2Qc-unsplash.jpg}

Todays goals:
\begin{list2}
\item How would you design a minimal production setup
\item Selecting technology -- some recommendations
\item Alerting and reporting -- what is available now in your systems
\end{list2}

  Photo by Thomas Galler on unsplash

\slide{Plan for today}

\begin{list1}
\item Subjects
\begin{list2}
\item Real systems, how to design
\item Technology options
\item A little Veris, and regular/yearly state-of-reports
\end{list2}
\item Exercise theme: Moving into a real deployment
\begin{list2}
\item Mostly discussion about options for deploying SIEM tools and technologies
\item Alerting and reporting
\end{list2}
\end{list1}

Follow up from last, \link{https://github.com/devdjdjdj/kibana-presenter}

\slide{Reading Summary}

\begin{list1}
\item DDS 7. Learning from Security Breaches VERIS
\item DDS 12. Moving Toward Data-Driven Security
\item IDIR 1. Introduction
\item IDIR 2. Basics of Intelligence
\end{list1}


\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}

\end{quote}

Source: DDS 7. Learning from Security Breaches VERIS
\begin{list2}
\item We all see the same attacks, make it easier to communicate between applications and organizations
\item Learn from others
\item Another example MITRE ATT\&CK® \link{https://attack.mitre.org/}
\end{list2}


\slide{Reading Summary, continued}

\hlkimage{8cm}{jay-data-science-workflow.png}

\begin{quote}
\begin{list2}
\item Find and Collect Relevant Data
\item Learn through Iteration
\item Find Statistics
\end{list2}

\end{quote}
Source: DDS 12. Moving Toward Data-Driven Security


\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}{\bf
Building a Real-Life Security Data Science Team}\\

... a clear goal: Given an IP address (or IP/Port combination), {\bf search across all our perimeter devices in less than five minutes.}

Three core principles focused the team.
\begin{list2}
\item First, explore the open source versions of tools before engaging vendors. If you don’t
know how the sausage is being made, you really have no idea what’s being done, and
this is vital when working with real data.
\item Second, follow the mantra of “no single tool; no single database; and, no single approach
to solving a problem.” Do not put blinders on because you are either comfortable with
certain technologies or have an affinity for a certain tool.
\item Third, failure is expected, but you must learn from each journey down the wrong path.
Continuous adaptation and adjustment is the name of the game.
\end{list2}
\end{quote}

Source: DDS 12. Moving Toward Data-Driven Security





\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}
When you begin implementing intelligence-driven incident response, it is important to have a solid understanding of both intelligence and incident-response processes. Part 1 provides an introduction to cyber-threat intelligence, the intelligence process, the incident-response process, and how they all work together.
\end{quote}
Source: IDIR 1. Introduction

\begin{list2}
\item Obviously a book about incident response, but a modern one
\end{list2}

\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}
There was a time when many people considered indicators of compromise, or IOCs, to be synonymous with threat intelligence. IOCs, which we will reference a lot and cover in depth later in the book, are things to look for on a system or in network logs that may indicate that a compromise has taken place. This includes IP addresses and domains associated with command-and-control servers or malware downloads, hashes of malicious files, and other network- or host-based artifacts that may indicate an intrusion. As we will discuss throughout this book, however, there is far more to threat intelligence than IOCs, although IOCs still remain one of the most common types of technical intelligence around intrusions.
\end{quote}
Source:  IDIR 2. Basics of Intelligence

\begin{list2}
\item List sources of intelligence, HUMINT, OSINT, SIGINT etc.
\item Introduces the OODA loop, “observe, orient, decide, act.” and the Intelligence Cycle
\item OODA loop also used in the SOC book
\end{list2}



\slide{Side note: redundancy}

%\hlkimage{}{}

\begin{quote}

\end{quote}

\begin{list2}
\item Redundancy can often be achieved in multiple ways
\item Two servers - physical servers
\item Two disks - RAID1 mirrors
\item OR using virtualisation
\item Redundancy is not an alternative to backup!
\item Make sure you plan for upgrades too! Upgrading one server while the other handle messages
\end{list2}



\slide{Drill down process}

%\hlkimage{}{}

\begin{quote}

\end{quote}

We have seen Kibana multiple times, but how do you use it? I recommend the following iterative process
\begin{enumerate}
\item Get an overview
\item Research top talkers,
\item When identified and handled, remove with filter \verb+not host 10.1.2.3+
\item Look at the next ones
\end{enumerate}

Look into details, lookup hostnames -- hopefully your tool allows some help




\slide{How to get started}

\begin{list1}
\item How to get started searching for security events?
\item Collect basic data from your devices and networks
\begin{list2}
\item Netflow data from routers
\item Session data from firewalls
\item Logging from applications: email, web, proxy systems
\end{list2}
\item {\bf Centralize!}
\item Process data
\begin{list2}
\item Top 10: interesting due to high frequency, occurs often, brute-force attacks
\item {\it ignore}
\item Bottom 10: least-frequent messages are interesting
\end{list2}
\end{list1}





\slide{Logstash pipeline }

\begin{quote}
  Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite “stash.” (Ours is Elasticsearch, naturally.)\\
  \link{https://www.elastic.co/products/logstash}
\end{quote}

\begin{verbatim}
input { stdin { } }
output {
  elasticsearch { host => localhost }
  stdout { codec => rubydebug }
}
\end{verbatim}



\begin{list2}
\item Logstash receives via {\bf input}
\item Processes with {\bf filters} - grok
\item Forward events with {\bf output}
\end{list2}


\slide{Logstash as SNMPtrap and syslog server}

{\footnotesize
\begin{verbatim}
input {
  snmptrap {
    host => "0.0.0.0"
    type => "snmptrap"
    port => 1062
    community => "xxxxx"   }
  tcp {
    port => 5000
    type => syslog  }
  udp {
    port => 5000
    type => syslog  }
}
\end{verbatim}
}

\begin{list2}
\item We run logstash on port 5000 - but use IPtables port forwarding
\item Have you even configured SNMP traps?
\item Maybe you have a device sending SNMP traps right now ...
\end{list2}

\slide{IPtables forwarding}

{\footnotesize
\begin{verbatim}
*nat
:PREROUTING ACCEPT [0:0]
# redirect all incoming requests on port 514 to port 5000
-A PREROUTING -p tcp --dport 514 -j REDIRECT --to-port 5000
-A PREROUTING -p udp --dport 514 -j REDIRECT --to-port 5000
-A PREROUTING -p udp --dport 162 -j REDIRECT --to-port 1062
COMMIT
\end{verbatim}
}

\centerline{Inserted near beginning of /etc/ufw/before.rules on Ubuntu}

Remember defense in depth, dont run a privileged Java VM process as root \smiley

\slide{Grok expresssions}

{\footnotesize
\begin{verbatim}
  filter {
    if [type] == "syslog" {
      grok {
        match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp}
        %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}
        (?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
        add_field => [ "received_at", "%{@timestamp}" ]
        add_field => [ "received_from", "%{host}" ]
      }
      syslog_pri { }
      date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
    }
  }
\end{verbatim}
}

\begin{list2}
\item Logstash filter expressions grok can normalize and split data into fields
\end{list2}

Source:
Config snippet from\\
{\small\link{http://logstash.net/docs/1.4.1/tutorials/getting-started-with-logstash}}



\slide{Lets design a SIEM Infrastructure Proof of Concept}

\hlkimage{16cm}{demo-siem-setup.pdf}


\slide{Deploying security}

\begin{quote}{\bf
Security is a process, not a product.} Products provide some protection, but the only way to effectively do business in an insecure world is to put processes in place that recognize the inherent insecurity in the products. The trick is to reduce your risk of exposure regardless of the products or patches.
\end{quote}
Source: \link{https://www.schneier.com/essays/archives/2000/04/the_process_of_secur.html}

Today, we will consider the deployment plan being:
\begin{list2}
\item People -- make sure management is on board, Sources -- which data to gather,
\item Technology -- select SIEM, architecture, tools and products
\item Dashboards -- we have done parts of this, refer to SOC book also
\item Procedures -- left as a home exercise today
\end{list2}



\slide{People: Data Analysis Skills}

\begin{quote}
Although we could spend an entire book creating an exhaustive list of skills needed to be a good security data scientist, this chapter covers the following skills/domains that a data scientist will benefit from
knowing within information security:
\begin{list2}
\item Domain expertise—Setting and maintaining a purpose to the analysis
\item Data management—Being able to prepare, store, and maintain data
\item Programming—The glue that connects data to analysis
\item Statistics—To learn from the data
\item Visualization—Communicating the results effectively
\end{list2}
It might be easy to label any one of these skills as the most important, but in reality, the whole is greater than the sum of its parts. Each of these contributes a significant and important piece to the workings of
security data science.
\end{quote}

Source: \emph{Data-Driven Security: Analysis, Visualization and Dashboards} Jay Jacobs, Bob Rudis\\
ISBN: 978-1-118-79372-5 February 2014 \url{https://datadrivensecurity.info/} - short DDS



\slide{People: Get management buy-in}

\hlkimage{6cm}{margarida-csilva-121801-unsplash.jpg}

You will probably need help from:

\begin{list2}
\item Buy-in from management, for requesting resources
\item Network and security departments -- getting data, opening ports
\item Application developers, web site programmers
\end{list2}
Lifeguard training photo by Margarida CSilva on Unsplash


\slide{Sources: Network overview without SIEM}

\hlkimage{15cm}{sample-ip-network.pdf}

\begin{quote}

\end{quote}

\begin{list2}
\item Internet, routers, firewalls, switches, clients and servers (Wi-Fi not shown)
\end{list2}


\slide{Sources: Strategy for implementing identification and detection}

We recommend that the following strategy is used for implementing identification and detection -- logging:
\begin{enumerate}
\item[\faSquareO] Enable system logging from servers
\item[\faSquareO] Enable system logging from network devices
\item[\faSquareO] Enable logging from client devices
\item[\faSquareO] Centralize logging
\item[\faSquareO] Add search facilities and dashboards
\item[\faSquareO] Perform system audits manually or automatically
\item[\faSquareO] Setup alerting and notification with procedures
\end{enumerate}

\slide{Extended Sources}
When a basic logging infrastructure is setup, it can be expanded to increase coverage, by
adding more sources:

\begin{list2}
\item DNS query logging -- will enable multiple cases to be resolved, example malware identification and tracing, when was a malware domain queried, when was the first infection
\item Web proxy logging -- which web pages did which client access
\item Session data from Firewalls, Netflow -- traffic patterns can be investigated and both attacks and cases like exfiltration can likely be seen

\end{list2}

Hint: Take the sources available first, make a proof-of-concept, expand coverage





\slide{Architecture: Tools}

%\hlkimage{}{}

\begin{quote}

\end{quote}

We will use the tools presented during the course:
\begin{list2}
\item Elastic stack: Elasticsearch, Logstash, Kibana, Filebeat, Packetbeat
\item Zeek and Suricata can easily be added at a later stage
\item Likewise DNS and web proxy logging could be added
\end{list2}

\vskip 1cm

The setup discussed here would be a good proof of conccept, and be valuable almost immediately

\slide{Elasticsearch}

\hlkimage{6cm}{demo-siem-setup-elasticsearch.pdf}


\begin{list2}
\item We plan to build a basic cluster with Elasticsearch, latest stable
\item Multiple ES nodes for easier upgrade, redundancy and performance
\item Each have 200Gb disk and 16Gb memory allocated
\end{list2}




\slide{Logstash -- syslog and SNMP trap receiver}

\hlkimage{6cm}{demo-siem-setup-logstash.pdf}

\begin{list2}
\item We have network devices which can only send syslog and SNMP trap -- \emph{push events from the network}
\item So enable inputs: snmptrap, tcp, udp and use UFW to redirect ports
\item We have made two servers, which use VRRP to have a common address
\end{list2}

\slide{Packetbeat}

\hlkimage{10cm}{demo-siem-setup-packetbeat.pdf}


\begin{list2}
\item By installing packetbeat and doing network mirroring from the network switch, we can gather a lot of information
\item Packetbeat supports Elastic Common Schema (ECS) \link{https://www.elastic.co/beats/packetbeat}
\item ICMP (v4 and v6)
DHCP (v4)
DNS
HTTP
AMQP 0.9.1
Cassandra
Mysql
PostgreSQL
Redis
Thrift-RPC
MongoDB
Memcache
NFS
TLS
SIP/SDP (beta)
\end{list2}


\slide{Application servers}

\hlkimage{3cm}{demo-siem-setup-servers.pdf}

\begin{quote}

\end{quote}

\begin{list2}
\item We told the server and application people to use Filebeat and Syslog
\item The Linux people decided to use syslog
\item Windows servers use Filebeat \link{}https://www.elastic.co/beats/filebeat
\item All of them send to the Logstash instances
\end{list2}

\slide{Baseline}

\hlkimage{10cm}{nfsen-ddos-profile-1.png}

\begin{list2}
\item Picture from NFsen running a specific profile to catch attacks
\item When you have a running system, it will start to gather a baseline
\item Comparing data from various times become possible, and usefull
\item The best baseline is from running the actual systems and services for an extended \emph{learning} period
\end{list2}

\slide{Alerting}

%\hlkimage{}{}

\begin{quote}\small
We’re excited to announce a new alerting framework that delivers a first-class alerting experience natively within the SIEM, Uptime, APM, and Metrics applications as part of the Kibana 7.7 release.

Alerting is a fundamental use case across the Elastic Stack, which is why we’re making it part of the core experience within Kibana. Whether you are monitoring application transactions or tracking brute force login attempts, our goal is to provide a tailored experience that allows you to build powerful alerts in the normal flow of your task. The new alerting framework is built from the ground up and designed to offer more than just convenient interfaces. We understand the need to go beyond just notifying people which is why we’ve also incorporated the ability to trigger predefined actions that can do anything from sending an email to using brand new third-party integrations with platforms like Slack and PagerDuty.

The new alerting framework is being introduced as a beta in the 7.7 release of Kibana and is available immediately on the Elasticsearch Service on Elastic Cloud, or for download.
\end{quote}

\begin{list2}
\item {\footnotesize\link{https://www.elastic.co/blog/introducing-the-new-alerting-framework-for-observability-security-and-the-elastic-stack}}
\item {\footnotesize\link{https://www.elastic.co/what-is/kibana-alerting}}
\item {\footnotesize\link{https://www.elastic.co/blog/alerting-in-the-elastic-stack}}
\end{list2}


\slide{Alerting everywhere}

%\hlkimage{}{}

\begin{quote}
Alerting everywhere: Kibana 7.7 introduces ubiquitous alerting for Elastic Observability, Elastic Security, and the Elastic Stack. Users can now create alerts directly from within the SIEM, APM, Metrics, and Uptime applications as well as for any index.
\end{quote}

\begin{list2}
\item Seems a lot has happened with alerting in the new version!
\item Lets try to work with the alerting framework, note: sending email can sometimes be tricky without some configuration.
\end{list2}

\exercise{ex:es7-alerting}


\slide{ES reporting}

%\hlkimage{}{}

\begin{quote}{\bf
Push a button, get a report. Easy.}\\
Kibana is a fantastic way to visualize and explore your Elasticsearch data. Its reporting features let you easily export your favorite Kibana visualizations and dashboards. Each report is print-optimized, customizable, and PDF-formatted. And the option to add your own logo will give your reports the branded, polished look that will color your team impressed.
\end{quote}
Source: \link{https://www.elastic.co/what-is/kibana-reporting}


\begin{list2}
\item Not sure I agree, but some features are available
\item Discussion! Writing and presenting are two very different things, so are dashboards and reports!
\end{list2}


\slide{Automating Report Generation}

\begin{quote}{\bf
Create a POST URL}\\
Create the POST URL that triggers a report to generate.
\end{quote}
Source: \link{https://www.elastic.co/guide/en/kibana/current/automating-report-generation.html}


\begin{list2}
\item Not sure I agree, but some features are available
\item I like the automated report generation, getting data pushed from ES is a great feature.
\item Correlation also added
\link{https://www.elastic.co/blog/whats-new-elastic-security-7-10-0-correlation-cloud-visibility-detection}

\end{list2}



\slide{Automatic reporting: tcpflow}

\hlkimage{8cm}{simpsong-tcpflow.png}

\begin{list2}
  \item \link{https://github.com/simsong/tcpflow}
  \item \emph{Passive TCP Reconstruction and Forensic Analysis with tcpflow}, Simson Garfinkel and Michael Shick, Naval Postgraduate School Technical Report NPS-CS-13-003, September 2013.
  \link{https://calhoun.nps.edu/handle/10945/36026}
\end{list2}



\slide{VERIS}

%\hlkimage{}{}

\begin{quote}
Verizon RISK Team. “2013 data breach investigations report.” Available at http://www.verizonenterprise.com/DBIR—This report is based on data collected using the VERIS framework. You might find it handy to look at some of the graphics in the report and then attempt to repeat them using the verisr package, discussed in this chapter, and the VCDB data.
\end{quote}
Source: DDS page 189


\slide{Automated IOC Formats}

\begin{quote}{\bf
Automated IOC Formats}

Fully automated and comprehensive formats such as OpenIOC and STIX are useful only for teams that use tools built for them (or are capable of of building tools to use these standards).
\end{quote}
Source: IDIR page 198


\begin{list2}
\item Veris and other standardized format are a benefit\\
\link{http://veriscommunity.net/}\\
\emph{VERIS the vocabulary for event recording and incident sharing}
\item Most come from a need, but few are implemented across the industry
\end{list2}

\centerline{What are some of the yearly reports you like?}


\slide{GDPR, logging and legality}

%\hlkimage{}{}

\begin{quote}
  10.Stiller GDPR krav om logning af alt, herunder hvad den enkelte bruger laver på
  systemet, hvad han ser mv.?

  SikkerhedsBranchens opfattelse er at det er nok at logge hvem der er logget ind i
  systemet i hvilket tidsrum. Princippet i den gamle persondatalovs § 41 stk. 3 er
  ført videre i GDPR, og praksis derfra understøtter vores opfattelse.
\end{quote}
Source: \link{https://www.sikkerhedsbranchen.dk/wp-content/uploads/2018/12/GDPR-Databeskyttelse-FAQ.pdf}

\begin{list2}
\item Most references are about GDPR and logging
\item Keywords gdpr siem site:dk
  \item \link{https://digst.dk/styring/standardkontrakter/klausuler-til-informationssikkerhed/logning/}
\end{list2}


\slide{Monitoring of employees}

%\hlkimage{}{}

\begin{quote}{\bf
  Overvågning på arbejdspladsen}

  På en tredjedel af IT-arbejdspladserne overvåges IT-medarbejdernes brug af e-mails og Internet. Det viser en lille stikprøveundersøgelse, som PROSA har foretaget. PROSA ønsker klare regler på området og vil derfor på en række møder være med til at sætte gang i overvågningsdebatten
\end{quote}
Source: 2001 PROSA {\footnotesize\link{https://www.prosa.dk/artikel/overvaagning-paa-arbejdspladsen-1/}}

\begin{list2}
  \item Also {\footnotesize\link{https://www.prosa.dk/artikel/regler-for-it-overvaagning-paa-arbejdspladsen/}}
\item If your IT-security policies allow private use of devices and systems, be careful
\item Even if your IT-security policies do not allow, people might store private data
\item If you need to access data, {\bf for operational purposes}, you ARE allowed in DK
\item Recommend informing employees and others specifically
\end{list2}

\slide{Danish Data Protection Agency: Employee data}

%\hlkimage{}{}

\begin{quote}
Databeskyttelse i forbindelse med ansættelsesforhold er et komplekst område, hvor bl.a. de overordnede databeskyttelsesretlige regler, ansættelsesretlige regler samt kollektive overenskomster og aftaler har betydning for de behandlinger af personoplysninger, der sker på arbejdspladser og i fagforeninger, mv.

Såvel offentlige som private arbejdsgivere behandler en stor mængde personoplysninger om ansøgere i forbindelse med rekruttering og om medarbejdere, både under ansættelsen og efter ansættelsens ophør. Tilsvarende behandler faglige organisationer og tillidsrepræsentanter personoplysninger om både deres medlemmer og andre medarbejdere på arbejdspladsen. Hertil kommer, at der i vidt omfang udveksles oplysninger mellem de enkelte aktører.
\end{quote}
Source: {\footnotesize\link{https://www.datatilsynet.dk/media/7597/databeskyttelse-i-forbindelse-med-ansaettelsesforhold.pdf}}

\begin{list2}
\item Probably one of the best sources to use, as they process complaints about data processing
\item 43 pages
\end{list2}


\slidenext{}


\end{document}
